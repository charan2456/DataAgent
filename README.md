<div align="center">

# ðŸ¤– Data Agent

### Autonomous Conversational Analytics Platform

An **Agentic AI system** that converts natural language into executable Python & SQL using LangChain ReAct agents â€” featuring autonomous tool selection, sandboxed code execution, persistent memory, and real-time streaming of reasoning steps.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Node.js 18+](https://img.shields.io/badge/node-18+-green.svg)](https://nodejs.org/)
[![LangChain](https://img.shields.io/badge/LangChain-Agent_Framework-orange)](https://github.com/langchain-ai/langchain)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED)](https://www.docker.com/)

</div>

---

## ðŸ’¡ Why I Built This

Most data analysis tools fall into two camps: **rigid BI dashboards** that can't handle ad-hoc questions, or **notebook environments** that require coding expertise. Neither works for the 90% of business users who have data questions but can't write SQL or Python.

**Data Agent** bridges this gap by turning an LLM into an autonomous analyst that can:
- Understand a vague business question ("*What's our best-performing product category this quarter?*")
- Autonomously decide which tool to use (SQL query? Python analysis? Visualization?)
- Execute code in a sandboxed environment and iterate if the first attempt fails
- Stream its reasoning process in real-time so users can follow along

This isn't just a ChatGPT wrapper â€” it's a **full agentic pipeline** with tool orchestration, memory management, and production-grade execution.

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DATA AGENT SYSTEM                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Frontend    â”‚     â”‚              Agent Core (ReAct Loop)             â”‚  â”‚
â”‚  â”‚              â”‚     â”‚                                                  â”‚  â”‚
â”‚  â”‚  Next.js     â”‚â”€â”€â”€â”€â–¶â”‚  User Query                                      â”‚  â”‚
â”‚  â”‚  TypeScript  â”‚     â”‚      â”‚                                           â”‚  â”‚
â”‚  â”‚  Material-UI â”‚     â”‚      â–¼                                           â”‚  â”‚
â”‚  â”‚  ECharts     â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚  â”‚
â”‚  â”‚  CodeMirror  â”‚     â”‚  â”‚  ConversationalChat â”‚                         â”‚  â”‚
â”‚  â”‚              â”‚     â”‚  â”‚      Agent          â”‚                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  (LangChain ReAct)  â”‚                         â”‚  â”‚
â”‚        â–²              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚  â”‚
â”‚        â”‚              â”‚            â”‚                                      â”‚  â”‚
â”‚        â”‚              â”‚            â–¼                                      â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚
â”‚  â”‚   Flask API   â”‚     â”‚  â”‚        Thought â†’ Action â†’ Observe   â”‚         â”‚  â”‚
â”‚  â”‚              â”‚â—€â”€â”€â”€â–¶â”‚  â”‚                                     â”‚         â”‚  â”‚
â”‚  â”‚  /api/chat   â”‚     â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚         â”‚  â”‚
â”‚  â”‚  /api/upload â”‚     â”‚  â”‚  â”‚ Thought  â”‚â”€â–¶â”‚  Action   â”‚         â”‚         â”‚  â”‚
â”‚  â”‚  /api/conv.  â”‚     â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚                    â”‚               â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚         â–¼          â–¼          â–¼    â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â”‚  Python   â”‚â”‚   SQL    â”‚â”‚EChartsâ”‚ â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â”‚  Code     â”‚â”‚  Query   â”‚â”‚Viz    â”‚ â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â”‚  Builder  â”‚â”‚  Builder â”‚â”‚Builderâ”‚ â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”¬â”€â”€â”€â”˜ â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚        â”‚          â”‚          â”‚     â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚        â–¼          â–¼          â–¼     â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â”‚     Observation (Results)     â”‚  â”‚         â”‚  â”‚
â”‚                       â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â”‚
â”‚                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        Infrastructure Layer                          â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ MongoDB  â”‚  â”‚  Redis   â”‚  â”‚ Jupyter/IPythonâ”‚  â”‚    Docker     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚          â”‚  â”‚          â”‚  â”‚   Kernel       â”‚  â”‚  (Sandboxed   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Messages â”‚  â”‚ Caching  â”‚  â”‚   Execution    â”‚  â”‚   Execution)  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ History  â”‚  â”‚ Session  â”‚  â”‚   Engine       â”‚  â”‚               â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Users    â”‚  â”‚ State    â”‚  â”‚                â”‚  â”‚               â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How the ReAct Agent Loop Works

```
User: "Show me the top 5 products by revenue"
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ THOUGHT: I need to query the data to find product revenue.      â”‚
â”‚          The user uploaded a CSV file. I'll use Python to        â”‚
â”‚          analyze it with pandas.                                 â”‚
â”‚                                                                  â”‚
â”‚ ACTION:  PythonCodeBuilder                                       â”‚
â”‚ INPUT:   "Load the uploaded CSV, group by product, sum revenue,  â”‚
â”‚           sort descending, take top 5"                           â”‚
â”‚                                                                  â”‚
â”‚ â”€â”€â”€â”€ Code Execution (Sandboxed Jupyter Kernel) â”€â”€â”€â”€              â”‚
â”‚ â”‚  import pandas as pd                                         â”‚ â”‚
â”‚ â”‚  df = pd.read_csv('uploaded_data.csv')                       â”‚ â”‚
â”‚ â”‚  top5 = df.groupby('product')['revenue'].sum()               â”‚ â”‚
â”‚ â”‚         .sort_values(ascending=False).head(5)                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                  â”‚
â”‚ OBSERVATION: Successfully returned top 5 products DataFrame      â”‚
â”‚                                                                  â”‚
â”‚ THOUGHT: Now I should visualize this as a bar chart for clarity  â”‚
â”‚                                                                  â”‚
â”‚ ACTION:  ECharts                                                 â”‚
â”‚ INPUT:   "Create a bar chart from the top 5 products data"       â”‚
â”‚                                                                  â”‚
â”‚ OBSERVATION: Chart rendered successfully                         â”‚
â”‚                                                                  â”‚
â”‚ FINAL ANSWER: "Here are your top 5 products by revenue..."       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> The agent **autonomously decides** which tools to invoke, chains multiple steps together, and self-corrects on errors â€” all without hardcoded workflow logic.

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ðŸ§  **ReAct Agent Loop** | Autonomous Thought â†’ Action â†’ Observation cycle using LangChain agents |
| ðŸ”§ **Dynamic Tool Selection** | Agent chooses between Python, SQL, visualization, and data loading tools |
| ðŸ **Sandboxed Code Execution** | Python/SQL runs in isolated Jupyter kernels (local or Docker) |
| ðŸ“Š **Auto-Visualization** | Generates interactive ECharts visualizations from natural language |
| ðŸ’¬ **Conversational Memory** | Persistent context across multi-turn conversations via MongoDB |
| âš¡ **Real-time Streaming** | Stream agent reasoning steps and code execution results live |
| ðŸ“ **Multi-format Data Input** | CSV, Excel, databases, and Kaggle dataset integration |
| ðŸ”’ **Production Security** | Docker-based sandboxed execution for untrusted code |

---

## ðŸ› ï¸ Tech Stack

### Agent & AI Layer
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Agent Framework | **LangChain** | ReAct agent orchestration, tool management, prompt chaining |
| LLM Support | **GPT-4, GPT-3.5, Claude v1/v2, Azure OpenAI** | Multi-model support with configurable endpoints |
| Code Execution | **Jupyter/IPython Kernels** | Sandboxed, stateful Python execution with variable persistence |
| Prompt Engineering | **Custom ReAct prompts** | Structured Thought/Action/Observation format with tool routing |

### Backend
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Web Framework | **Flask** | REST API server with streaming support |
| Database | **MongoDB** | Persistent storage for conversations, messages, and users |
| Caching | **Redis** | Session state, kernel management, and performance caching |
| Process Management | **Multiprocess + Threading** | Concurrent kernel execution and background task management |

### Frontend
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Framework | **Next.js + TypeScript** | Server-side rendering, type safety |
| UI Library | **Material-UI** | Professional component library |
| Visualization | **ECharts** | Interactive, responsive data visualizations |
| Code Editor | **CodeMirror** | Syntax-highlighted code display and editing |
| Styling | **Tailwind CSS** | Utility-first responsive styling |

---

## ðŸ”§ Agent Tools Deep Dive

Each tool is autonomously selected by the agent based on the user's intent:

### `PythonCodeBuilder`
```
Trigger:  "Analyze this data", "Calculate the average", "Clean the dataset"
Process:  Generates Python code â†’ Executes in Jupyter kernel â†’ Returns results
Capable:  pandas, numpy, scikit-learn, matplotlib â€” full data science stack
```

### `SQLQueryBuilder`
```
Trigger:  "Query the database", "Find all records where...", "Join these tables"
Process:  Generates SQL â†’ Validates syntax â†’ Executes against connected DB â†’ Returns results
Capable:  Complex JOINs, aggregations, window functions, subqueries
```

### `ECharts (Visualization)`
```
Trigger:  "Show me a chart", "Visualize this", "Plot the trend"
Process:  Analyzes data shape â†’ Selects chart type â†’ Generates ECharts config â†’ Renders interactive chart
Capable:  Bar, line, scatter, pie, heatmap, and custom chart types
```

### `KaggleDataLoader`
```
Trigger:  "Find a dataset about...", "Load the Titanic dataset"
Process:  Searches Kaggle API â†’ Downloads dataset â†’ Loads into session â†’ Ready for analysis
Capable:  Search by keyword, download by URL, automatic CSV/Excel parsing
```

---

## ðŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/charan2456/DataAgent.git
cd DataAgent

# Setup backend
cd backend
pip install -r requirements.txt
export OPENAI_API_KEY=your_key_here
python main.py

# Setup frontend (in new terminal)
cd frontend
npm install
export NEXT_PUBLIC_BACKEND_ENDPOINT=http://localhost:8000
npm run dev
```

Visit `http://localhost:3000` to start using Data Agent!

---

## ðŸ“¦ Installation (Detailed)

### Prerequisites

- Python 3.10+
- Node.js 18+
- MongoDB
- Redis
- OpenAI API Key (or compatible LLM API)

### Backend Setup

1. Create Python environment:
```bash
conda create -n data-agent python=3.10
conda activate data-agent
```

2. Install dependencies:
```bash
cd backend
pip install -r requirements.txt
```

3. Set environment variables:
```bash
export OPENAI_API_KEY=your_key_here
export MONGO_SERVER=127.0.0.1
export REDIS_SERVER=127.0.0.1
export CODE_EXECUTION_MODE=local  # or "docker" for production
```

4. Initialize MongoDB:
```bash
mongosh
> use data_agent
> db.createCollection("user")
> db.createCollection("message")
> db.createCollection("conversation")
> db.createCollection("folder")
```

5. Run backend:
```bash
python main.py
```

### Frontend Setup

1. Install dependencies:
```bash
cd frontend
npm install
```

2. Set environment variables:
```bash
export NEXT_PUBLIC_BACKEND_ENDPOINT=http://localhost:8000
```

3. Run frontend:
```bash
npm run dev
```

4. Open browser at `http://localhost:3000`

---

## ðŸ³ Docker Deployment

```bash
# Update environment variables in docker-compose.yml
# Then build and start:
docker-compose build
docker-compose up -d
```

### Code Execution Modes

| Mode | Security | Performance | Use Case |
|------|----------|-------------|----------|
| `local` | âš ï¸ Code runs on host | âš¡ Fast | Development, trusted environments |
| `docker` | âœ… Isolated containers | Normal | **Production** â€” sandboxed execution |

```bash
export CODE_EXECUTION_MODE=docker  # Recommended for production
```

---

## ðŸ“¡ API Reference

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/chat` | POST | Main chat endpoint â€” sends user query, returns agent response with streaming |
| `/api/conversation` | POST | Retrieve full conversation history by ID |
| `/api/conversations/get_conversation_list` | POST | List all conversations for a user |
| `/api/upload` | POST | Upload CSV, Excel, or database files for analysis |
| `/api/llm_list` | GET | Get available language models |

---

## ðŸ§© Project Structure

```
DataAgent/
â”œâ”€â”€ backend/                    # Flask API Server
â”‚   â”œâ”€â”€ api/                   # REST API endpoints
â”‚   â”œâ”€â”€ main.py                # Application entry point & memory pool initialization
â”‚   â”œâ”€â”€ app.py                 # Flask app configuration
â”‚   â”œâ”€â”€ schemas.py             # Request/response schemas
â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚
â”œâ”€â”€ real_agents/                # ðŸ§  Agent Intelligence Layer
â”‚   â”œâ”€â”€ adapters/              # Shared infrastructure
â”‚   â”‚   â”œâ”€â”€ llm.py            # Custom LLMChain with DataModel support
â”‚   â”‚   â”œâ”€â”€ agent_helpers/    # Agent base classes & output parsing
â”‚   â”‚   â”œâ”€â”€ callbacks/        # Streaming & logging callbacks
â”‚   â”‚   â”œâ”€â”€ data_model/       # Data model abstractions (25 files)
â”‚   â”‚   â”œâ”€â”€ executors/        # Tool execution engines
â”‚   â”‚   â”œâ”€â”€ memory/           # Conversation memory management
â”‚   â”‚   â””â”€â”€ models/           # LLM model configurations
â”‚   â”‚
â”‚   â””â”€â”€ data_agent/            # Data Agent implementation
â”‚       â”œâ”€â”€ copilot.py        # ConversationalChatAgent (ReAct agent core)
â”‚       â”œâ”€â”€ copilot_prompt.py # System prompts & ReAct format instructions
â”‚       â”œâ”€â”€ executors/        # Tool-specific executors
â”‚       â”‚   â”œâ”€â”€ code_generation_executor.py
â”‚       â”‚   â”œâ”€â”€ data_summary_executor.py
â”‚       â”‚   â””â”€â”€ kaggle_data_loading_executor.py
â”‚       â”œâ”€â”€ python/           # Python code execution tools
â”‚       â”œâ”€â”€ sql/              # SQL query execution tools
â”‚       â””â”€â”€ evaluation/       # Response evaluation
â”‚
â”œâ”€â”€ frontend/                   # Next.js Frontend (107 files)
â”‚   â”œâ”€â”€ components/            # React UI components
â”‚   â”œâ”€â”€ pages/                 # Next.js pages
â”‚   â””â”€â”€ styles/                # Tailwind CSS configuration
â”‚
â”œâ”€â”€ docker-compose.yml          # Multi-container Docker deployment
â”œâ”€â”€ Dockerfile                  # Backend container definition
â””â”€â”€ TECHNICAL_DOCUMENTATION.md  # In-depth technical reference
```

---

## ðŸ”¬ Technical Highlights

### 1. Custom ReAct Implementation
Unlike basic LangChain agent setups, Data Agent implements a **custom `ConversationalChatAgent`** that extends the base agent with:
- **Scratchpad optimization** â€” Constructs AI message history efficiently to minimize token usage
- **Token budget management** â€” Dynamic truncation of chat history to stay within model context limits (8K tokens)
- **Continue prompts** â€” Model-specific continuation strategies for long-running reasoning chains
- **Tool response templating** â€” Structured observation format that guides the agent's next reasoning step

### 2. Stateful Code Execution
The Jupyter/IPython kernel maintains **state across turns**, meaning:
```
Turn 1: "Load this CSV"           â†’ df variable persists
Turn 2: "Filter rows where x > 5" â†’ Operates on existing df
Turn 3: "Plot the results"         â†’ Uses filtered df from Turn 2
```

### 3. Multi-Model Architecture
The LLM layer supports **hot-swapping models** between:
- OpenAI (GPT-3.5, GPT-4)
- Anthropic (Claude v1, v2)
- Azure OpenAI
- Any OpenAI-compatible endpoint (local LLMs via Ollama, vLLM, etc.)

### 4. Memory Architecture
```
MongoDB (Persistent)           Redis (Session)
â”œâ”€â”€ Conversations             â”œâ”€â”€ Active kernel sessions
â”œâ”€â”€ Messages                  â”œâ”€â”€ Cached query results
â”œâ”€â”€ User profiles             â””â”€â”€ Temporary state
â””â”€â”€ Uploaded file metadata
```

---

## ðŸ“Š Performance Characteristics

| Metric | Value | Notes |
|--------|-------|-------|
| Agent Response Time | ~3-8s | Depends on LLM model and tool complexity |
| Code Execution | <2s | Average for standard pandas operations |
| Visualization Render | <1s | ECharts client-side rendering |
| Context Window | 8K tokens | With dynamic truncation for longer conversations |
| Concurrent Users | Multi-user | Thread-safe kernel pool management |
| Supported File Sizes | Up to 100MB | CSV/Excel file processing |

---

## ðŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ðŸ“ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- Built with [LangChain](https://github.com/langchain-ai/langchain)
- UI components from [Material-UI](https://mui.com/)
- Visualization powered by [ECharts](https://echarts.apache.org/)

## ðŸ“§ Support

For issues and questions:
- Open an issue on [GitHub Issues](https://github.com/charan2456/DataAgent/issues)
